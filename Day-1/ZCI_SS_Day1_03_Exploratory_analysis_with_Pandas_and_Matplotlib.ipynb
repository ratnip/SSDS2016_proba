{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Summer School - Split '16 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1 - Python for data analysis fundamentals \n",
    "### *Numpy, Pandas, Matplotlib*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) 2016 Damir Pintar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*version: 0.1* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kernel: Python 2.7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Exploratory analysis with Pandas and Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final chapter we will very briefly demonstrate the process of exploratory data analysis of a new dataset using *Pandas* and *Matplotlib* pakcages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 2 we have been working on a small data frame, which was relatively easy to analize simply by printing it out in entirety and then visually inspecting individual cells. In practice, this is very rarely the case. Most of the time the dataset will have a lot more columns and potentially hundreds, thousands or perhaps millions of rows. Visually inspecting such dataset is out of the question, so we have to use alternative methods to gain insight into the information within."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the more common questions for the exploratory analysis process are:\n",
    "- what metadata about the dataset do I have available?\n",
    "- how many rows and columns does the dataset have?\n",
    "- what is the data type of each column?\n",
    "- are there any missing values in the table and if yes, where?\n",
    "- what is the distribution of numerical and categorical variables?\n",
    "- what is the nature of relationships between individual columns?\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the first question, for which we usually must go to the dataset's source and/or communicate with the domain experts, other questions may be answered by performing exploratory analysis using provided functions for statistical calculations as well as various visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate an example of a (brief) exploratory analysis using the popular `Titanic` dataset, which describes passengers of cruise ship Titanic which sank  sank in the North Atlantic Ocean on 15 April 1912, after colliding with an iceberg during her maiden voyage from Southampton to New York City. This dataset contains attributes such as passengers` names, title, the amount they paid for the fare, their passenger class, port of origin etc. with the most important attribute being the one denoting whether the passenger survived the disaster or not. The dataset is usually used for predictive analysis which tries to find relationships between various attributes and the passenger's ultimate fate. This is in fact the subject of currently ongoing *Kaggle* competition, which can be accessed here <a href = \"https://www.kaggle.com/c/titanic/data\">[1]</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic dataset should be avaiable in the current working directory as `Titanic.csv`. The link above is a great way to collect the metadata for this dataset and should be our first stop for gaining information about what is actually contained in the dataset (in the chance that the link is not working, the reader should try to discover alternate source of metadata, which shouldn;t be difficult for this particular dataset due to its popularity). We will assume you have given at least a cursory glance to the dataset's metadata and that you have at least a rough idea about its contents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let us now proceed with exploratory analysis. We will first import the necessary packages and then read our CSV file with the already learned `read.csv` method from the *Pandas* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "titanic_df = pd.read_csv(\"Titanic.csv\", index_col = \"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will find out the following:\n",
    "- dimensions of this data frame\n",
    "- names of columns\n",
    "- data types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out data frames dimensions throuth its shape attribute\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out the names of the columns via columns attribute\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prnit out the data types of columns using the dtypes attribute\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there was something seriously wrong with our loaded dataset, we would be aware by looking at the above results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to get a little information about the data itself. There is a handy method called `info()` which gives us a nicely formated summary of our dataset (and is often the very first function the analyst calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call the info method on titanic_df\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `info()` method provides a lot of information, including some that we retrieved later using other methods. Notice that we also gained some information about how many missing values will have - and certain columns seem to have quite a lot of them. We will need to keep this in mind in our further exploration of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides `info()`, one of the most popular functions analysts use is the `describe` method of the `DataFrame` object. This method will provide a statistical overview of all numerical columns, or even *all* columns if we include the `include = 'all'` parameter. Try calling this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# call the describe method of titanic_df\n",
    "# use include = 'null' as an argument\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to carefully analyze the information you have gained. For numerical columns you have essentially gained the popular \"five number summary\" and for categorical you have at least some idea what the top category is and what is its frequency. We have quite a lot of `NaN`s, but that is because a) certain columns have missing values and b) certain measures aren't applicable to certain columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might pay closer attention to the `Survived` attribute. Initially we may dismiss this information as useless since `Survived` is obviously a categorical, or better said boolean attribute and we seem to have gained a numerical summary. However, if we remember that `False` is here most probably coded as `0`, and `True` as `1`, we may easily conclude that the average mean of this attribute is actually the survival rate of passengers - pretty useful information. In fact, analysts very commonly count sum and mean of \"boolean\" columns to get quick insight into absolute counts or ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the \"description\" of the dataset, it is very common for the analysts to want to check out how actual rows look like. For that there are a few popular methods - `head` which will show a few rows from the beginning, and `tail` which will show a few lines from the end. We can control the number of lines by providing a specific numerical paramater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out the first 5 rows from titanic_df by using the head method\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out the last 10 rows from titanic_df by using the tail method\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point there are plenty of possible follow-up options: trying to deal with missing values, checking for outliers or points with high leverage, deriving new columns from the existing ones etc. For our final strecth of this lecture, we will provide a glimplse on one of the most important aspects of exploratory analysis - data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visualizing our dataset using various graph type we can reveal and easily process a wealth of important information from our dataset. One of the most popular Python packages for visualization is `matplotlib`. We can import it now as `plt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib` package is used for visualization and plotting. To achieve this, `matplotlib` uses a special `Figure` object. When using Jupyter Notebooks, it's convenient to create a new figure before every graph using the method `figure`. We can also conviently set the figure size with the `figsize` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One note about `matplotlib` - while very powerful and flexible, it is not really user-friendly. To get the most out of it, you will need to be closely acquainted with both *Numpy* and *Pandas*, since `matplotlib` often wants you to prepare the data in a specific way before calling the plotting function. To alleviate potential problems with `matplotlib`, we suggest you become fluent in *Numpy* and *Pandas* first, and to pay attention to the official documentation of the package (available here: <a href = \"#3\">[3]</a>). Also, at the end of this lecture you will find links to some alternatives to `matplotlib` which you may find easier to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the simplest possible graph - a *scatterplot*. The following graph simply puts observations on the x-axis, and the value of the chosen attribute on the y-values. We will create a scatterplot for the `Fare` attribute - on the x-axis we have put the indexes (basically integers from 0 to the number of rows), and on the y-axis we have place the price of the fare, sorted in an ascending order.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(x = titanic_df.index, y = titanic_df.Fare.sort_values(), c = 'red', alpha = 0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the semicolon (;) in the end of the previous statement. This is important if we want to supress unwanted output from the `plt.scatter` statement (and other similar statements).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the graph itself, we can see that the fare price seems to have been exponential in nature - vast majority of passengers paid less than \\$100, while one passenger paid the then astronomical price of over \\$500. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we examine a single numerical variable, we commonly want to estimate its distribution shape by drawing a histogram. Let's create one for the `Age` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we will create a histogram with a few additional parameters (number of bins, color and alpha)\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(titanic_df.Age.dropna(), bins = 50, facecolor = 'g', alpha = 0.6);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the distribution of ages which might be approximately normal, with the mean around 30. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables, we commonly use a bar plot. We need to do some pre-processing for this - we will first call the `value_counts` method of the `DataFrame` object which will calculate total numbers for each category, then we will sort the resulting `Series` by indexes, and finally plot it directly with the `plot` method setting the `kind` attribute as `bar` and providing a few additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "titanic_df.Pclass.value_counts().sort_index().plot(kind = 'bar', color = 'orange', alpha = 0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, vast majority of the passengers were in the 3rd class, while the rest were relatively evenly split between 1st and second klass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular plot is the boxplot. Let's now do something more fancy and actually show the `Age` attribute split by a grid of two categorical variables - `Sex` and `Pclass`. For this we will call the wrapper method `boxplot` from the `DataFrame` object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boxplot is actually called as a DataFrame method\n",
    "plt.figure(figsize=(7,5));\n",
    "titanic_df.dropna().boxplot(column = 'Age',  by = ['Pclass'], return_type = \"axes\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One drawback of the `matplotlib` library as that it is relatively low-level, meaning that to get the most out of its feature, you reakky have to understand the inner complexities and inner workings, especially concerning its synergy with the *Numpy* and *Pandas* libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's say that we want to see how gender and passenger class related to the ultimate fate of the passenger. To show this, we fisrt need to adequately pre-preocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subframe = titanic_df[['Sex', 'Pclass', 'Survived']].copy()\n",
    "subframe['Died'] = subframe.Survived == 0\n",
    "subframe_group = subframe.groupby(['Sex', 'Pclass']).sum()\n",
    "subframe_group.unstack().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the graph seems to show is that most victims by far were male passengers from the third passenger class, while most likely to survive were female passengers from the 1st and 2nd class. Of course we need to remember that this conclusion doesn't tkae into account the initial ratio of passengers - we need to remember that male 3rd class passengers were in the majority, so it was to be expected that they might have proportionally end up with most victims.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will here conclude our brief introduction to exploratory analysis. To unlock the full potential of the `matplotlib` package, reader is encouraged to check out the official `matplotlib` user's guide at <a href = \"http://matplotlib.org/users/intro.html\">[3]</a>. Also for some visualization alternatives, we can suggest checking out packages such as: \n",
    "- <a href = \"http://bokeh.pydata.org/en/latest/\">`Bokeh`</a> - a visualization library oriented towards web graphics \n",
    "- <a href = \"http://stanford.edu/%7Emwaskom/software/seaborn/#\">`Seaborn`</a> - a popular visualization library based on `matplotlib`\n",
    "- <a href = \"http://lightning-viz.org/\">`Lightning`</a> - also a web-oriented visualization library\n",
    "- <a href = \"https://github.com/sirrice/pygg\">`pygg`</a> - a Python wrapper for the extremely popular `ggplot2` visualization library from the `R` programming language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we conclude our introductory chapter of using Python for data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <hr> <hr>\n",
    "## <font color = \"blue\">Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`1.` In the working directory of this notebook you will find three more datasets:\n",
    "- iris.csv\n",
    "- mtcars.csv\n",
    "- diamonds.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these datasets are extremely popular in the data science community. Try applying what you have learned and perform a thorough exploratory analysis on these datasets. Remember to search the web for the metadata to gain understanding about the information contained within before embarking on the analysis itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr> <hr> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"1\"></a><a href = \"https://www.kaggle.com/c/titanic\">[1]</a> *Titanic: Machine learning from disaster*, Kaggle competition, last accessed 2016/09/06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"2\"></a><a href = \"http://pandas.pydata.org/pandas-docs/stable/api.html#series\">[2]</a> *Series and Data Frame API Reference*, official Pandas documentation, last accessed 2016/09/06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = \"3\"></a><a href = \"http://matplotlib.org/users/intro.html\">[3]</a> *Introduction to Matplotlib*, official *matplotlib*  documentation, last accessed 2016/09/07"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
